#!/usr/bin/env python3
"""
Tool test kh·∫£ nƒÉng nh·∫≠n di·ªán h√¨nh ·∫£nh tr√™n c√°c ƒë·ªô ph√¢n gi·∫£i kh√°c nhau
"""

import os
import sys
import cv2
import numpy as np
import pyautogui
import tkinter as tk
from PIL import Image, ImageTk

def get_screen_info():
    """L·∫•y th√¥ng tin m√†n h√¨nh"""
    root = tk.Tk()
    screen_width = root.winfo_screenwidth()
    screen_height = root.winfo_screenheight()
    root.destroy()
    
    aspect_ratio = screen_width / screen_height
    
    # Classify screen type
    if abs(aspect_ratio - 16/9) < 0.1:
        aspect_type = "16:9"
    elif abs(aspect_ratio - 16/10) < 0.1:
        aspect_type = "16:10"
    elif abs(aspect_ratio - 4/3) < 0.1:
        aspect_type = "4:3"
    else:
        aspect_type = f"{aspect_ratio:.2f}:1"
    
    # Estimate screen size
    if screen_width <= 1366:
        size_category = "Small (‚â§13.3\")"
    elif screen_width <= 1920:
        size_category = "Medium (14-15.6\")"
    else:
        size_category = "Large (‚â•17\")"
    
    return {
        'width': screen_width,
        'height': screen_height,
        'aspect_ratio': aspect_ratio,
        'aspect_type': aspect_type,
        'size_category': size_category
    }

def test_multi_scale_detection(image_name, confidence=0.8):
    """Test multi-scale detection cho m·ªôt h√¨nh ·∫£nh"""
    image_path = os.path.join("image", image_name)
    if not os.path.exists(image_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y {image_name}")
        return None
    
    print(f"üîç Testing detection cho {image_name}...")
    
    # Ch·ª•p m√†n h√¨nh
    screenshot = pyautogui.screenshot()
    screenshot_cv = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)
    
    # ƒê·ªçc template
    template = cv2.imread(image_path)
    if template is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc {image_name}")
        return None
    
    print(f"üìè Template size: {template.shape[1]}x{template.shape[0]}")
    
    # Test multiple scales
    scales = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]
    results = []
    
    for scale in scales:
        # Resize template
        if scale != 1.0:
            new_width = int(template.shape[1] * scale)
            new_height = int(template.shape[0] * scale)
            
            if new_width < 10 or new_height < 10:
                continue
            if new_width > screenshot_cv.shape[1] or new_height > screenshot_cv.shape[0]:
                continue
                
            scaled_template = cv2.resize(template, (new_width, new_height))
        else:
            scaled_template = template
        
        # Template matching
        result = cv2.matchTemplate(screenshot_cv, scaled_template, cv2.TM_CCOEFF_NORMED)
        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
        
        results.append({
            'scale': scale,
            'confidence': max_val,
            'location': max_loc,
            'template_size': (scaled_template.shape[1], scaled_template.shape[0])
        })
        
        status = "‚úÖ" if max_val >= confidence else "‚ùå"
        print(f"  Scale {scale:.2f}: {status} confidence={max_val:.3f} at {max_loc} (size: {scaled_template.shape[1]}x{scaled_template.shape[0]})")
    
    # T√¨m k·∫øt qu·∫£ t·ªët nh·∫•t
    best_result = max(results, key=lambda x: x['confidence'])
    print(f"üéØ Best match: scale={best_result['scale']:.2f}, confidence={best_result['confidence']:.3f}")
    
    return best_result

def test_all_images():
    """Test t·∫•t c·∫£ h√¨nh ·∫£nh trong th∆∞ m·ª•c image"""
    print("=" * 60)
    print("TEST MULTI-SCALE IMAGE DETECTION")
    print("=" * 60)
    
    # Hi·ªÉn th·ªã th√¥ng tin m√†n h√¨nh
    screen_info = get_screen_info()
    print(f"üì∫ M√†n h√¨nh: {screen_info['width']}x{screen_info['height']}")
    print(f"üìê T·ª∑ l·ªá: {screen_info['aspect_type']} ({screen_info['aspect_ratio']:.3f})")
    print(f"üì± Lo·∫°i: {screen_info['size_category']}")
    print()
    
    # L·∫•y danh s√°ch t·∫•t c·∫£ h√¨nh ·∫£nh
    image_dir = "image"
    if not os.path.exists(image_dir):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {image_dir}")
        return
    
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not image_files:
        print(f"‚ùå Kh√¥ng c√≥ h√¨nh ·∫£nh trong th∆∞ m·ª•c {image_dir}")
        return
    
    # Test t·ª´ng h√¨nh ·∫£nh
    confidence_threshold = 0.7
    results = {}
    
    for image_file in sorted(image_files):
        print(f"\n{'='*40}")
        result = test_multi_scale_detection(image_file, confidence_threshold)
        results[image_file] = result
    
    # T·ªïng k·∫øt
    print(f"\n{'='*60}")
    print("T·ªîNG K·∫æT")
    print("=" * 60)
    
    detected_count = sum(1 for r in results.values() if r and r['confidence'] >= confidence_threshold)
    total_count = len(results)
    
    print(f"üìä T·ªïng s·ªë h√¨nh ·∫£nh: {total_count}")
    print(f"‚úÖ Ph√°t hi·ªán ƒë∆∞·ª£c: {detected_count}")
    print(f"‚ùå Kh√¥ng ph√°t hi·ªán: {total_count - detected_count}")
    print(f"üìà T·ª∑ l·ªá th√†nh c√¥ng: {(detected_count/total_count)*100:.1f}%")
    
    # ƒê·ªÅ xu·∫•t c·∫•u h√¨nh t·ªëi ∆∞u
    print(f"\nüîß ƒê·ªÄ XU·∫§T C·∫§U H·ªành:")
    
    # T√≠nh confidence trung b√¨nh c·ªßa c√°c detection th√†nh c√¥ng
    successful_confidences = [r['confidence'] for r in results.values() 
                            if r and r['confidence'] >= confidence_threshold]
    
    if successful_confidences:
        avg_confidence = sum(successful_confidences) / len(successful_confidences)
        recommended_confidence = max(0.5, avg_confidence - 0.1)  # Th·∫•p h∆°n 10% ƒë·ªÉ an to√†n
        print(f"   Confidence ƒë·ªÅ xu·∫•t: {recommended_confidence:.2f}")
    else:
        print(f"   Confidence ƒë·ªÅ xu·∫•t: 0.6 (do kh√¥ng c√≥ detection th√†nh c√¥ng)")
    
    # Screen-specific recommendations
    if screen_info['width'] <= 1366:
        print("   M√†n h√¨nh nh·ªè: N√™n s·ª≠ d·ª•ng multi-scale detection")
        print("   ƒê·ªÅ xu·∫•t: confidence 0.6-0.7, enable rotation detection")
    elif screen_info['width'] <= 1920:
        print("   M√†n h√¨nh trung b√¨nh: C·∫•u h√¨nh chu·∫©n")
        print("   ƒê·ªÅ xu·∫•t: confidence 0.7-0.8, multi-scale khi c·∫ßn")
    else:
        print("   M√†n h√¨nh l·ªõn: C√≥ th·ªÉ d√πng confidence cao h∆°n")
        print("   ƒê·ªÅ xu·∫•t: confidence 0.8-0.9, √≠t c·∫ßn multi-scale")

def main():
    if len(sys.argv) > 1:
        # Test m·ªôt h√¨nh ·∫£nh c·ª• th·ªÉ
        image_name = sys.argv[1]
        confidence = 0.8
        if len(sys.argv) > 2:
            confidence = float(sys.argv[2])
        
        screen_info = get_screen_info()
        print(f"üì∫ M√†n h√¨nh: {screen_info['width']}x{screen_info['height']} ({screen_info['aspect_type']})")
        print()
        
        test_multi_scale_detection(image_name, confidence)
    else:
        # Test t·∫•t c·∫£ h√¨nh ·∫£nh
        test_all_images()

if __name__ == "__main__":
    main()